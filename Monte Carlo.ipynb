{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monte Carlo Simulations for NLLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_batch, fit_biExponential_model_signal, read_data, rRMSE_per_case\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from model import PIA\n",
    "from torch import optim\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dir='../public_training_data/'\n",
    "file_Resultdir='../Result/'\n",
    "fname_gt ='_IVIMParam.npy'\n",
    "fname_gtDWI ='_gtDWIs.npy'\n",
    "fname_tissue ='_TissueType.npy'\n",
    "fname_noisyDWIk = '_NoisyDWIk.npy'\n",
    "\n",
    "\n",
    "b_values = [0, 5, 50, 100, 200, 500, 800, 1000]\n",
    "test_tensor, f_test, D_test, D_star_test, clean = get_batch(10, noise_sdt=0.01)\n",
    "#test = test_tensor.detach().cpu().numpy()\n",
    "#f, D, D_star = fit_biExponential_model_signal(test, b_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "class PIA(nn.Module):\n",
    "    def __init__(self, b_values = [0, 5, 50, 100, 200, 500, 800, 1000],\n",
    "                hidden_dims= [32, 64, 128, 256, 512],\n",
    "                predictor_depth=2):\n",
    "         super(PIA, self).__init__()\n",
    "\n",
    "         self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "         self.number_of_signals = len(b_values)\n",
    "         self.sigmoid = nn.Sigmoid()\n",
    "         modules = []\n",
    "         in_channels = self.number_of_signals\n",
    "         for h_dim in hidden_dims:\n",
    "             modules.append(nn.Sequential(\n",
    "                 nn.Linear(in_features=in_channels, out_features=h_dim),\n",
    "                 nn.LeakyReLU()))\n",
    "             in_channels = h_dim\n",
    "         self.encoder = nn.Sequential(*modules).to(self.device)\n",
    "         D_predictor = []\n",
    "         for _ in range(predictor_depth):\n",
    "             D_predictor.append(nn.Sequential(\n",
    "                 nn.Linear(in_features=hidden_dims[-1], out_features=hidden_dims[-1]),\n",
    "                 nn.LeakyReLU())\n",
    "                 )\n",
    "         D_predictor.append(nn.Linear(hidden_dims[-1], 1))\n",
    "         self.D_predictor = nn.Sequential(*D_predictor).to(self.device)\n",
    "    def encode(self, x):\n",
    "        \"\"\"\n",
    "        Encodes the input by passing through the encoder network\n",
    "        and returns the latent codes.\n",
    "        :param input: (Tensor) Input tensor to encoder\n",
    "        :return: (Tensor) List of latent codes\n",
    "        \"\"\"\n",
    "        result = self.encoder(x)   \n",
    "        D = self.D_predictor(result)\n",
    "        # D_star = 3 + self.relu(self.D_star_predictor(result))\n",
    "        # f = self.sigmoid(self.f_predictor(result))      \n",
    "        return D#[f, D, D_star]\n",
    "\n",
    "# D_star_predictor = []\n",
    "# for _ in range(predictor_depth):\n",
    "    \n",
    "#     D_star_predictor.append(\n",
    "#         nn.Sequential(\n",
    "#             nn.Linear(in_features=hidden_dims[-1], out_features=hidden_dims[-1]),\n",
    "#             nn.LeakyReLU())\n",
    "#     )\n",
    "# D_star_predictor.append(nn.Linear(hidden_dims[-1], 1))\n",
    "# D_star_predictor = nn.Sequential(*D_star_predictor).to(device)\n",
    "# f_predictor = []\n",
    "# for _ in range(predictor_depth):\n",
    "    \n",
    "#     f_predictor.append(\n",
    "#         nn.Sequential(\n",
    "#             nn.Linear(in_features=hidden_dims[-1], out_features=hidden_dims[-1]),\n",
    "#             nn.LeakyReLU())\n",
    "#     )\n",
    "# f_predictor.append(nn.Linear(hidden_dims[-1], 1))\n",
    "# f_predictor = nn.Sequential(*f_predictor).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PIA()\n",
    "params = model.parameters()\n",
    "lr = 3e-4\n",
    "optimizer = optim.Adam(params, lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "test_tensor = test_tensor.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0153\n",
      "0.0613\n",
      "0.0069\n",
      "0.0073\n",
      "0.0069\n",
      "0.0070\n",
      "0.0070\n",
      "0.0067\n",
      "0.0068\n",
      "0.0066\n",
      "0.0065\n",
      "0.0062\n",
      "0.0054\n",
      "0.0036\n",
      "0.0013\n",
      "0.0000\n",
      "0.0016\n",
      "0.0006\n",
      "0.0000\n",
      "0.0002\n",
      "0.0000\n",
      "0.0015\n",
      "0.0021\n",
      "0.0002\n",
      "0.0000\n",
      "0.0057\n",
      "0.0000\n",
      "0.0003\n",
      "0.0000\n",
      "0.0000\n",
      "0.0000\n",
      "0.0000\n",
      "0.0000\n",
      "0.0000\n",
      "0.0000\n",
      "0.0000\n",
      "0.0000\n",
      "0.0000\n",
      "0.0000\n",
      "0.0000\n",
      "0.0000\n",
      "0.0000\n",
      "0.0000\n",
      "0.0000\n",
      "0.0000\n",
      "0.0000\n",
      "0.0000\n",
      "0.0000\n",
      "0.0000\n",
      "0.0000\n"
     ]
    }
   ],
   "source": [
    "clean = clean.to(device)\n",
    "f_test = f_test.to(device)\n",
    "D_test = D_test.to(device)\n",
    "loss_fcn = nn.MSELoss()\n",
    "model.train()\n",
    "for ep in range(500):\n",
    "    for i in range(10):\n",
    "        D = model.encode(test_tensor[i])\n",
    "        #D_star = 5 + D_star_predictor(result)\n",
    "        #f = sigmoid(f_predictor(result))\n",
    "        #signal = torch.zeros((D.shape[0], number_of_signals)).to(device)\n",
    "        # D_T, D_star_T, f_T = D.T, D_star.T, f.T\n",
    "        # for inx, b in enumerate(b_values):\n",
    "        #     signal[:, inx] = (1-f_T)*torch.exp(-(b/1000)*D_T) + f_T*torch.exp(-(b/1000)*D_star_T)\n",
    "    \n",
    "        loss = torch.mean((D - D_test[i]) ** 2)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if not ep%10:\n",
    "        print(f'{loss.item():.4f}')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = model.encode(test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8995],\n",
       "        [1.4721],\n",
       "        [0.3933],\n",
       "        [2.3882],\n",
       "        [2.4022],\n",
       "        [0.2531],\n",
       "        [0.7275],\n",
       "        [1.9818],\n",
       "        [1.3470],\n",
       "        [0.1006]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8995, 1.4721, 0.3933, 2.3882, 2.4022, 0.2531, 0.7275, 1.9818, 1.3470,\n",
       "        0.1006], device='cuda:0')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = \"cuda:0\"\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "device = torch.device(dev)\n",
    "#models =  []\n",
    "torch.cuda.empty_cache()\n",
    "model = PIA(predictor_depth=2).float().to(device).train()\n",
    "params = model.parameters()\n",
    "lr = 3e-4\n",
    "optimizer = optim.Adam(params, lr=lr)\n",
    "test_tensor = test_tensor.cuda()\n",
    "\n",
    "clean = clean.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [00:00<00:13,  3.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4933]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([0.2338])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/50 [00:00<00:09,  4.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4989]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([0.2338])\n",
      "tensor([[0.5046]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([0.2338])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4/50 [00:00<00:09,  5.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5105]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([0.2338])\n",
      "tensor([[0.5165]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([0.2338])\n",
      "tensor([[0.5231]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([0.2338])\n",
      "tensor([[0.5304]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([0.2338])\n",
      "tensor([[0.5385]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([0.2338])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 9/50 [00:01<00:04, 10.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5476]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([0.2338])\n",
      "tensor([[0.5576]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([0.2338])\n",
      "tensor([[0.5686]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([0.2338])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 12/50 [00:01<00:04,  8.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5796]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([0.2338])\n",
      "tensor([[0.5884]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([0.2338])\n",
      "tensor([[0.5932]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([0.2338])\n",
      "tensor([[0.5941]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([0.2338])\n",
      "tensor([[0.5919]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([0.2338])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 17/50 [00:01<00:02, 11.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5878]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([0.2338])\n",
      "tensor([[0.5824]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([0.2338])\n",
      "tensor([[0.5767]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([0.2338])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20/50 [00:02<00:03,  9.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5712]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([0.2338])\n",
      "tensor([[0.5662]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([0.2338])\n",
      "tensor([[0.5618]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([0.2338])\n",
      "tensor([[0.5582]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([0.2338])\n",
      "tensor([[0.5553]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([0.2338])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25/50 [00:02<00:02, 12.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5531]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([0.2338])\n",
      "tensor([[0.5516]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([0.2338])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 32/50 [00:02<00:01, 14.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5506]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([0.2338])\n",
      "tensor([[0.5502]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([0.2338])\n",
      "tensor([[0.5501]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([0.2338])\n",
      "tensor([[0.5504]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([0.2338])\n",
      "tensor([[0.5509]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([0.2338])\n",
      "tensor([[0.5516]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([0.2338])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35/50 [00:03<00:01, 13.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5524]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([0.2338])\n",
      "tensor([[0.5531]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([0.2338])\n",
      "tensor([[0.5537]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([0.2338])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 37/50 [00:03<00:01, 10.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5539]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([0.2338])\n",
      "tensor([[0.5537]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([0.2338])\n",
      "tensor([[0.5531]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([0.2338])\n",
      "tensor([[0.5520]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([0.2338])\n",
      "tensor([[0.5504]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([0.2338])\n",
      "tensor([[0.5485]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([0.2338])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 42/50 [00:03<00:00, 12.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5463]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([0.2338])\n",
      "tensor([[0.5440]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([0.2338])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 44/50 [00:04<00:00,  9.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5416]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([0.2338])\n",
      "tensor([[0.5394]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([0.2338])\n",
      "tensor([[0.5372]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([0.2338])\n",
      "tensor([[0.5352]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([0.2338])\n",
      "tensor([[0.5335]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([0.2338])\n",
      "tensor([[0.5320]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([0.2338])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:04<00:00, 10.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5306]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([0.2338])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for ep in tqdm(range(50)):\n",
    "    optimizer.zero_grad()\n",
    "    f, D, D_star = model.encode(test_tensor)  \n",
    "    recon = model.decode(f, D, D_star).cuda()\n",
    "    loss = model.loss_function(recon, clean)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f, f_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4810])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_number in range(3):\n",
    "    nlls = np.load(os.path.join(file_Resultdir, f'{(image_number + 1):04d}.npy'))\n",
    "    params = read_data(file_dir, fname_gt, image_number + 1)\n",
    "fig, ax = plt.subplots(3,1, figsize=(15,45))\n",
    "title = ['f ', 'D ', 'D_star']\n",
    "ylims = [(0.0, 1.0), (0.0, 0.003), (0.003, 0.3)]\n",
    "for c in range(3):\n",
    "    y = nlls[:, :, c].flatten() \n",
    "    x = params[:, :, c].flatten()\n",
    "    #nbins=30\n",
    "    #k = gaussian_kde([x,y])\n",
    "    #xi, yi = np.mgrid[x.min():x.max():nbins*1j, y.min():y.max():nbins*1j]\n",
    "    #zi = k(np.vstack([xi.flatten(), yi.flatten()]))\n",
    "    #ax[c].pcolormesh(xi, yi, zi.reshape(xi.shape), cmap=\"hot\", shading='auto')\n",
    "    ax[c].scatter(x,y, color='b', s=4, alpha=0.5)\n",
    "\n",
    "    err = np.mean(np.abs(x - y))\n",
    "    corr = np.corrcoef(x,y)[0,1]\n",
    "    ax[c].xaxis.set_tick_params(labelsize=20)\n",
    "    ax[c].yaxis.set_tick_params(labelsize=20)\n",
    "    #ax[r,c].set_title(fr'{title[c]}, MAE = {err:.3f}, $\\rho$ = {corr:.3f}')\n",
    "    ax[c].set_xlabel('true', fontsize=24)\n",
    "    ax[c].set_ylabel('predicted', fontsize=24)\n",
    "\n",
    "\n",
    "\n",
    "#     tissue = read_data(file_dir, fname_tissue, image_number + 1)\n",
    "#     print(rRMSE_per_case(nlls[:,:,0],nlls[:,:,1],nlls[:,:,2],params[:,:,0],params[:,:,1],params[:,:,2],tissue))\n",
    "    #k = read_data(file_dir, fname_noisyDWIk, image_number)\n",
    "    #\n",
    "    #clean = read_data(file_dir, fname_gtDWI, image_number)\n",
    "    #clean_real = np.real(clean[:, :, 0])\n",
    "    #noisy = np.abs(np.fft.ifft2(k, axes=(0,1) ,norm='ortho'))\n",
    "    #coordBody = np.argwhere(clean > 0)\n",
    "    #pure_noise_re[b_value].append(noisy_real[coordBody[:,0], coordBody[:,1]] - clean_real[coordBody[:,0], coordBody[:,1]])\n",
    "    #f_measurement = params[:, :, 0]\n",
    "    #D_measurement = params[:, :, 1]\n",
    "    #D_star_measurement = params[:, :, 2]\n",
    "    #\n",
    "    #f.append(f_measurement[coordBody[:,0], coordBody[:,1]])\n",
    "    #D.append(D_measurement[coordBody[:,0], coordBody[:,1]])\n",
    "    #D_star.append(D_star_measurement[coordBody[:,0], coordBody[:,1]])\n",
    "\n",
    "\n",
    "# f = np.concatenate(f).ravel()\n",
    "# a = plt.hist(f, bins=100)\n",
    "# plt.title('f')\n",
    "\n",
    "# plt.figure()\n",
    "# D = np.concatenate(D).ravel()\n",
    "# a = plt.hist(D, bins=100)\n",
    "# plt.title('D')\n",
    "\n",
    "# plt.figure()\n",
    "# D_star = np.concatenate(D_star).ravel()\n",
    "# a = plt.hist(D_star, bins=100)\n",
    "# plt.title('D_star')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
