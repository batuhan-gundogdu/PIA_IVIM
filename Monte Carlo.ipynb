{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method - 1 Supervised Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "from utils import read_data, rRMSE_per_case #get_batch, fit_biExponential_model_signal\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Addresses\n",
    "file_dir='../public_training_data/'\n",
    "fname_gt ='_IVIMParam.npy'\n",
    "fname_gtDWI ='_gtDWIs.npy'\n",
    "fname_tissue ='_TissueType.npy'\n",
    "fname_noisyDWIk = '_NoisyDWIk.npy'\n",
    "file_Resultdir='../Result/'\n",
    "\n",
    "b_values = [0, 5, 50, 100, 200, 500, 800, 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7233413566918498 0.5567931568118685\n"
     ]
    }
   ],
   "source": [
    "# Save NLLS performance\n",
    "tumor, non_tumor = 0, 0\n",
    "ctr = 0\n",
    "for image_number in range(800, 1000):\n",
    "    nlls = np.load(os.path.join(file_Resultdir, f'{(image_number + 1):04d}.npy'))\n",
    "    params = read_data(file_dir, fname_gt, image_number + 1)\n",
    "    tissue = read_data(file_dir, fname_tissue, image_number + 1)\n",
    "    t, nt = rRMSE_per_case(nlls[:,:,0], nlls[:,:,1], nlls[:,:,2], params[:,:,0], params[:,:,1], params[:,:,2], tissue)\n",
    "    tumor += t\n",
    "    non_tumor += nt\n",
    "    ctr += 1\n",
    "print(tumor/ctr, non_tumor/ctr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PIA(nn.Module):\n",
    "    \n",
    "    def __init__(self, b_values = [0, 5, 50, 100, 200, 500, 800, 1000],\n",
    "                hidden_dims= [32, 64, 128, 256, 512],\n",
    "                predictor_depth=2):\n",
    "         super(PIA, self).__init__()\n",
    "\n",
    "         self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "         self.number_of_signals = len(b_values)\n",
    "         self.sigmoid = nn.Sigmoid()\n",
    "         modules = []\n",
    "         in_channels = self.number_of_signals\n",
    "         for h_dim in hidden_dims:\n",
    "             modules.append(nn.Sequential(\n",
    "                 nn.Linear(in_features=in_channels, out_features=h_dim),\n",
    "                 nn.LeakyReLU()))\n",
    "             in_channels = h_dim\n",
    "         self.encoder = nn.Sequential(*modules).to(self.device)\n",
    "         D_predictor = []\n",
    "         for _ in range(predictor_depth):\n",
    "             D_predictor.append(nn.Sequential(\n",
    "                 nn.Linear(in_features=hidden_dims[-1], out_features=hidden_dims[-1]),\n",
    "                 nn.LeakyReLU())\n",
    "                 )\n",
    "         D_predictor.append(nn.Linear(hidden_dims[-1], 1))\n",
    "         self.D_predictor = nn.Sequential(*D_predictor).to(self.device)\n",
    "    def encode(self, x):\n",
    "        \"\"\"\n",
    "        Encodes the input by passing through the encoder network\n",
    "        and returns the latent codes.\n",
    "        :param input: (Tensor) Input tensor to encoder\n",
    "        :return: (Tensor) List of latent codes\n",
    "        \"\"\"\n",
    "        result = self.encoder(x)   \n",
    "        D = self.D_predictor(result)\n",
    "        # D_star = 3 + self.relu(self.D_star_predictor(result))\n",
    "        # f = self.sigmoid(self.f_predictor(result))      \n",
    "        return D#[f, D, D_star]\n",
    "\n",
    "# D_star_predictor = []\n",
    "# for _ in range(predictor_depth):\n",
    "    \n",
    "#     D_star_predictor.append(\n",
    "#         nn.Sequential(\n",
    "#             nn.Linear(in_features=hidden_dims[-1], out_features=hidden_dims[-1]),\n",
    "#             nn.LeakyReLU())\n",
    "#     )\n",
    "# D_star_predictor.append(nn.Linear(hidden_dims[-1], 1))\n",
    "# D_star_predictor = nn.Sequential(*D_star_predictor).to(device)\n",
    "# f_predictor = []\n",
    "# for _ in range(predictor_depth):\n",
    "    \n",
    "#     f_predictor.append(\n",
    "#         nn.Sequential(\n",
    "#             nn.Linear(in_features=hidden_dims[-1], out_features=hidden_dims[-1]),\n",
    "#             nn.LeakyReLU())\n",
    "#     )\n",
    "# f_predictor.append(nn.Linear(hidden_dims[-1], 1))\n",
    "# f_predictor = nn.Sequential(*f_predictor).to(device)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if what you build is correct\n",
    "for image_number in range(1):\n",
    "    params = read_data(file_dir, fname_gt, image_number + 1)\n",
    "    clean = read_data(file_dir, fname_gtDWI, image_number + 1)\n",
    "    tissue = read_data(file_dir, fname_tissue, image_number + 1)\n",
    "    coordBody = np.argwhere(tissue != 1)\n",
    "    k = read_data(file_dir, fname_noisyDWIk, image_number + 1)\n",
    "    noisy = np.abs(np.fft.ifft2(k, axes=(0,1) ,norm='ortho'))\n",
    "    clean = np.abs(clean)\n",
    "\n",
    "    for pix in range(250, coordBody.shape[0]):\n",
    "        ix, jx = coordBody[pix, 0], coordBody[pix, 1]\n",
    "        f, D, D_star = params[ix, jx, :]\n",
    "        D *= 1000\n",
    "        D_star *=1000\n",
    "        print(clean[ix, jx]/clean[ix, jx, 0])\n",
    "        print(noisy[ix, jx]/clean[ix, jx, 0])\n",
    "        signal = np.zeros((len(b_values)), dtype=float)\n",
    "        for ctr, b in enumerate(b_values):\n",
    "            signal[ctr] = (1 - f)*np.exp(-(b/1000)*D) + f*np.exp(-(b/1000)*D_star)\n",
    "        print(signal)\n",
    "        break\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "from model import PIA\n",
    "from torch import optim\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_tensor, f_test, D_test, D_star_test, clean = get_batch(10, noise_sdt=0.01)\n",
    "#test = test_tensor.detach().cpu().numpy()\n",
    "#f, D, D_star = fit_biExponential_model_signal(test, b_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PIA()\n",
    "params = model.parameters()\n",
    "lr = 3e-4\n",
    "optimizer = optim.Adam(params, lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "test_tensor = test_tensor.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = clean.to(device)\n",
    "f_test = f_test.to(device)\n",
    "D_test = D_test.to(device)\n",
    "loss_fcn = nn.MSELoss()\n",
    "model.train()\n",
    "for ep in range(500):\n",
    "    for i in range(10):\n",
    "        D = model.encode(test_tensor[i])\n",
    "        #D_star = 5 + D_star_predictor(result)\n",
    "        #f = sigmoid(f_predictor(result))\n",
    "        #signal = torch.zeros((D.shape[0], number_of_signals)).to(device)\n",
    "        # D_T, D_star_T, f_T = D.T, D_star.T, f.T\n",
    "        # for inx, b in enumerate(b_values):\n",
    "        #     signal[:, inx] = (1-f_T)*torch.exp(-(b/1000)*D_T) + f_T*torch.exp(-(b/1000)*D_star_T)\n",
    "    \n",
    "        loss = torch.mean((D - D_test[i]) ** 2)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if not ep%10:\n",
    "        print(f'{loss.item():.4f}')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = \"cuda:0\"\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "device = torch.device(dev)\n",
    "#models =  []\n",
    "torch.cuda.empty_cache()\n",
    "model = PIA(predictor_depth=2).float().to(device).train()\n",
    "params = model.parameters()\n",
    "lr = 3e-4\n",
    "optimizer = optim.Adam(params, lr=lr)\n",
    "test_tensor = test_tensor.cuda()\n",
    "\n",
    "clean = clean.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ep in tqdm(range(50)):\n",
    "    optimizer.zero_grad()\n",
    "    f, D, D_star = model.encode(test_tensor)  \n",
    "    recon = model.decode(f, D, D_star).cuda()\n",
    "    loss = model.loss_function(recon, clean)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f, f_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig, ax = plt.subplots(3,1, figsize=(15,45))\n",
    "title = ['f ', 'D ', 'D_star']\n",
    "ylims = [(0.0, 1.0), (0.0, 0.003), (0.003, 0.3)]\n",
    "for c in range(3):\n",
    "    y = nlls[:, :, c].flatten() \n",
    "    x = params[:, :, c].flatten()\n",
    "    #nbins=30\n",
    "    #k = gaussian_kde([x,y])\n",
    "    #xi, yi = np.mgrid[x.min():x.max():nbins*1j, y.min():y.max():nbins*1j]\n",
    "    #zi = k(np.vstack([xi.flatten(), yi.flatten()]))\n",
    "    #ax[c].pcolormesh(xi, yi, zi.reshape(xi.shape), cmap=\"hot\", shading='auto')\n",
    "    ax[c].scatter(x,y, color='b', s=4, alpha=0.5)\n",
    "\n",
    "    err = np.mean(np.abs(x - y))\n",
    "    corr = np.corrcoef(x,y)[0,1]\n",
    "    ax[c].xaxis.set_tick_params(labelsize=20)\n",
    "    ax[c].yaxis.set_tick_params(labelsize=20)\n",
    "    #ax[r,c].set_title(fr'{title[c]}, MAE = {err:.3f}, $\\rho$ = {corr:.3f}')\n",
    "    ax[c].set_xlabel('true', fontsize=24)\n",
    "    ax[c].set_ylabel('predicted', fontsize=24)\n",
    "\n",
    "\n",
    "\n",
    "#     \n",
    "#     \n",
    "\n",
    "\n",
    "    #pure_noise_re[b_value].append(noisy_real[coordBody[:,0], coordBody[:,1]] - clean_real[coordBody[:,0], coordBody[:,1]])\n",
    "    #f_measurement = params[:, :, 0]\n",
    "    #D_measurement = params[:, :, 1]\n",
    "    #D_star_measurement = params[:, :, 2]\n",
    "    #\n",
    "    #f.append(f_measurement[coordBody[:,0], coordBody[:,1]])\n",
    "    #D.append(D_measurement[coordBody[:,0], coordBody[:,1]])\n",
    "    #D_star.append(D_star_measurement[coordBody[:,0], coordBody[:,1]])\n",
    "\n",
    "\n",
    "# f = np.concatenate(f).ravel()\n",
    "# a = plt.hist(f, bins=100)\n",
    "# plt.title('f')\n",
    "\n",
    "# plt.figure()\n",
    "# D = np.concatenate(D).ravel()\n",
    "# a = plt.hist(D, bins=100)\n",
    "# plt.title('D')\n",
    "\n",
    "# plt.figure()\n",
    "# D_star = np.concatenate(D_star).ravel()\n",
    "# a = plt.hist(D_star, bins=100)\n",
    "# plt.title('D_star')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
